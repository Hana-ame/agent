# AIå†™çš„README.md

## ğŸ“Œ é¡¹ç›®ç®€ä»‹

`kimi.py` æ˜¯ä¸€ä¸ªé«˜çº§çš„æ‰“å­—æœºæ•ˆæœ HTTP å®¢æˆ·ç«¯ï¼Œä¸“ä¸ºè°ƒç”¨ OpenAI å…¼å®¹ API è®¾è®¡ã€‚å®ƒæ”¯æŒæ–‡ä»¶é™„ä»¶ï¼ˆåŒ…æ‹¬å›¾ç‰‡å’Œæ–‡æœ¬ï¼‰ã€å‚æ•°å®‰å…¨å¤„ç†ã€æµå¼å“åº”ã€ä»¥åŠä¼˜é›…çš„é”™è¯¯å›é€€æœºåˆ¶ï¼Œç¡®ä¿åœ¨é‡åˆ°ä¸æ”¯æŒçš„å‚æ•°æˆ–ç½‘ç»œé—®é¢˜æ—¶ä¸ä¼šå´©æºƒã€‚

---

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½

### ğŸ§  æ‰“å­—æœºå¼è¾“å‡º
- ä»¥æ‰“å­—æœºæ•ˆæœé€å­—æ˜¾ç¤ºå“åº”å†…å®¹ï¼Œå¢å¼ºäº¤äº’ä½“éªŒ
- æ”¯æŒæµå¼ï¼ˆ`stream`ï¼‰å’Œéæµå¼ï¼ˆ`non-stream`ï¼‰å“åº”å¤„ç†

### ğŸ“ æ–‡ä»¶æ”¯æŒ
- æ”¯æŒ `@filename` è¯­æ³•ç›´æ¥é™„åŠ æ–‡ä»¶
- æ”¯æŒå¸¸è§å›¾åƒæ ¼å¼ï¼ˆPNG/JPG/GIF/WEBP/BMPï¼‰
- è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬ç¼–ç ï¼ˆUTF-8, GBK, Latin-1 ç­‰ï¼‰

### ğŸ›¡ï¸ å‚æ•°å®‰å…¨å¤„ç†
- é›¶é»˜è®¤ç­–ç•¥ï¼šé¿å…æ„å¤–ä½¿ç”¨ä¸æ”¯æŒçš„å‚æ•°
- ä¼˜é›…å›é€€ï¼šCLI å‚æ•°ä¼˜å…ˆäºé…ç½®æ–‡ä»¶ï¼Œé…ç½®æ–‡ä»¶ä¼˜å…ˆäºç¯å¢ƒå˜é‡
- è‡ªåŠ¨æ¸…ç†æ— æ•ˆå‚æ•°ï¼ˆå¦‚ `None` å€¼ã€ç©ºå­—ç¬¦ä¸²ï¼‰

### ğŸ“ é…ç½®ç®¡ç†
- æ”¯æŒ `config.json` ä½œä¸ºè¯·æ±‚ä½“é…ç½®
- æ”¯æŒ `profiles.json` æˆ– `.env` æ–‡ä»¶ç®¡ç† API ç«¯ç‚¹å’Œå¯†é’¥
- å¯é€šè¿‡ `--profile` æŒ‡å®šé¢„è®¾é…ç½®

### ğŸ“¤ ç»“æœä¿å­˜
- è‡ªåŠ¨ä¿å­˜ä¸º Markdown (`*.md`) å’Œ JSON (`*.json`) æ ¼å¼
- åŒ…å«å®Œæ•´å¯¹è¯å†å²ã€æ€è€ƒè¿‡ç¨‹ã€ç»Ÿè®¡ä¿¡æ¯

---

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
pip install requests python-dotenv
```

---

## ğŸ§© ä½¿ç”¨æ–¹å¼

```bash
python kimi.py "Your prompt here"
```

### åŸºç¡€ç”¨æ³•
```bash
# ä¸å¸¦å‚æ•°è¿è¡Œï¼ˆä½¿ç”¨é»˜è®¤é…ç½®ï¼‰
python kimi.py "Hello, how are you?"

# é™„åŠ æ–‡ä»¶ï¼ˆæ”¯æŒå›¾ç‰‡å’Œæ–‡æœ¬ï¼‰
python kimi.py @image.png "Describe this image"
python kimi.py @code.py "Explain this code"
```

### é«˜çº§é…ç½®
```bash
# æŒ‡å®šé…ç½®æ–‡ä»¶å’Œ profile
python kimi.py -p my_profile -c custom_config.json "Custom prompt"

# ç»§ç»­å¯¹è¯ï¼ˆä½¿ç”¨ä¹‹å‰çš„ JSON è¾“å‡ºï¼‰
python kimi.py --context conversation.json "Continue the conversation"

# ç¦ç”¨æµå¼è¾“å‡º
python kimi.py --no-stream "Generate a long response"

# è¦†ç›–å‚æ•°ï¼ˆå¦‚æ¸©åº¦ã€æœ€å¤§ tokensï¼‰
python kimi.py --temperature 0.5 --max-tokens 2000 "Creative writing"
```

---

## ğŸ“‹ å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ |
|------|------|
| `--profile` / `-p` | ä½¿ç”¨æŒ‡å®š profileï¼ˆé»˜è®¤ `default`ï¼‰ |
| `--endpoint` / `-e` | è¦†ç›– API ç«¯ç‚¹ |
| `--api-key` / `-k` | è¦†ç›– API å¯†é’¥ |
| `--config` / `-c` | æŒ‡å®šè¯·æ±‚ä½“é…ç½®æ–‡ä»¶ï¼ˆé»˜è®¤ `config.json`ï¼‰ |
| `--context` | ä½¿ç”¨å¯¹è¯å†å² JSON æ–‡ä»¶ç»§ç»­å¯¹è¯ |
| `--no-stream` | ç¦ç”¨æµå¼è¾“å‡º |
| `--enable-thinking` / `--no-thinking` | å¯ç”¨/ç¦ç”¨æ€è€ƒè¿‡ç¨‹è¾“å‡º |
| `--output` / `-o` | æŒ‡å®šè¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤è‡ªåŠ¨å‘½åï¼‰ |

---

## ğŸ“œ ç¤ºä¾‹é…ç½®æ–‡ä»¶

`config.json` ç¤ºä¾‹ï¼š
```json
{
  "model": "qwen-plus",
  "messages": [
    {"role": "user", "content": "What's the capital of France?"}
  ],
  "temperature": 0.7,
  "max_tokens": 100
}
```

`profiles.json` ç¤ºä¾‹ï¼š
```json
{
  "default": {
    "endpoint": "https://api.example.com/v1/completions",
    "api_key": "your_api_key_here"
  },
  "deepseek": {
    "endpoint": "https://api.deepseek.com/v1/completions",
    "api_key": "deepseek_api_key"
  }
}
```

---

## ğŸ“Œ æ³¨æ„äº‹é¡¹

1. **Token é™åˆ¶**  
   - é¢„ä¼° token æ•°ï¼ˆæ¯ 3 å­—ç¬¦ â‰ˆ 1 tokenï¼‰  
   - æ³¨æ„ OpenAI å…¼å®¹ API çš„ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶ï¼ˆå¦‚ 32k/128k tokensï¼‰

2. **æ–‡ä»¶å¤§å°**  
   - æ”¯æŒå¤§æ–‡ä»¶ä¸Šä¼ ï¼Œä½†éœ€æ³¨æ„ API çš„æ–‡ä»¶å¤§å°é™åˆ¶

3. **å‚æ•°å†²çª**  
   - CLI å‚æ•°ä¼šå®‰å…¨è¦†ç›–é…ç½®æ–‡ä»¶ä¸­çš„å‚æ•°  
   - ä¸æ”¯æŒçš„å‚æ•°ï¼ˆå¦‚ `temperature` ä¸ç‰¹å®šæ¨¡å‹å†²çªï¼‰ä¼šè¢«è‡ªåŠ¨ç§»é™¤

4. **å®‰å…¨å»ºè®®**  
   - ä¸è¦å°† API å¯†é’¥ç¡¬ç¼–ç åœ¨è„šæœ¬ä¸­  
   - ä½¿ç”¨ `.env` æ–‡ä»¶æˆ– profiles.json ç®¡ç†æ•æ„Ÿä¿¡æ¯

---

## ğŸ“ è¾“å‡ºç¤ºä¾‹

```markdown
# AI Conversation Log
**Time**: 2023-10-05 14:30:00  
**Model**: qwen-plus  
**Duration**: 1.23s  

## Request Configuration
```json
{
  "model": "qwen-plus",
  "temperature": 0.7,
  "max_tokens": 100
}
```

## Conversation History

### USER
Hello, how are you?

## ğŸ’­ Thinking Process
<details>
<summary>Click to expand (123 chars)</summary>
This is the thinking process...
</details>

## âœ¨ Response
This is the final response...

## ğŸ“Š Statistics
- **Finish Reason**: stop
- **Tokens**: 150 (Prompt: 50, Completion: 100)
- **Token Rate**: 123.4 tokens/s
