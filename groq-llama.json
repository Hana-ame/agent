{
  "messages": [],
  "model": "meta-llama/llama-4-maverick-17b-128e-instruct",
  "temperature": 1,
  "max_completion_tokens": 8192,
  "max_tokens": 8192,
  "top_p": 1,
  "stream": true,
  "stop": null
}